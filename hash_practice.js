/* In JavaScript, all non-scalar objects behave as associative arrays
The object can use other objects as keys. However, the length of the
associative array is not tracked (like with index-based arrays) and there
is the potential that the keys can conflict with built-in members (such
  as those added to the object prototype) and custom members such as the
  length property or convenience methods. We'll explore an approach that
  can avoid these shortcomings. */

/* A short example of an associative array (hash table) in JavaScript
is as follows: */

var h = new Object(); // or just {}
h['one'] = 1;
h['two'] = 2;
h['three'] = 3;

// show the values stored
for (var k in h) {
  // use hasOwnProperty to filter out keys from the Object.prototype
  if (h.hasOwnProperty(k)) {
    console.log('key is: ' + k + ', value is: ' + h[k]);
  }
}
// https://medium.com/@jschapir/cracking-the-coding-interview-hash-tables-backed-by-linked-list-a57e60885d78
/* First, let’s define the Hash Table. A hash table is generally backed by
an array and contains “buckets” to store data at each array index. The
hash table uses a hashing function to map values given to the function
to indexes in the array. At each index in the array, a bucket exists. So,
for example, we insert the value “hello world” into the hash table, the
table “hashes” the value and decides which index to store the string
“hello world” at. Due to the nature of the hashing function, it is
possible that multiple values may hash to the same index (a collision).
If this occurs, we can use a secondary data structure, like a Linked
List (my implementation), to store the multiple values at that index.
This is what I implemented to today. */

/* Check out the code: */

var HashTable = function(size) {
  var _list = [];
  this.size = size || 0;
  HashTable.prototype.insert = function(val) {
    //retrieve index via hashing function for value
    var index = this.hash(val, this.size);
    //check if index contains LL
    var bucket = _list[index];
    //if not create new linked list with val being the head of the list
    if (!bucket) {
      _list[index] = new Node(val);
    } else {
      var current = _list[index]; //first node in bucket

      if (current.value == val) {
        //node exists
        return;
      }
      while (current.next) {
        //another value exists in the LL

        current = current.next; //traverse ll

        if (current.value == val) {
          //collision
          console.log('collision');
          return;
        }
      }
      //set the tail of the list to equal the new value
      current.next = new Node(val);
    }
  };
  HashTable.prototype.getList = function() {
    return _list;
  };
};
HashTable.prototype.hash = function(str, max) {
  var hash = 0;
  for (var i = 0; i < str.length; i++) {
    hash = (hash << 5) + hash + str.charCodeAt(i);
    hash = hash & hash; // Convert to 32bit integer
    hash = Math.abs(hash);
  }
  return hash % max;
};

//Node of Linked List
var Node = function(val) {
  this.value = val;
  this.next = null;
};
module.exports = HashTable;

/* Hashmap summary:
As you know, operations on data structures can take a varying amount of
time. Depending on what you are using a structure for, you need to be
quite careful with your structure choice, as the performance/resource
impact can be quite impressive.

For instance, appending elements to a LinkedList has a constant time O(1),
but accessing elements by index on that LinkedList will take O(n/2) in
average, O(n) in the worst case scenario (accessing the last element by
  index) and O(1) in the best case scenario (accessing the first element
    by index).

So, what's the benefit of using LinkedList? their ability to insert and
remove elements anywhere in the structure without having to shift all the
elements to a new position. You should use them when you have an algorithm
that makes insertions/deletions of elements in a sequence in arbitrary
positions. Accessing a LinkedList by index is a PITA, but traversing it
with an iterator is pretty quick, as the iterator only needs to keep
track of the current element and the next one in the structure.

But you asked about HashMaps and hashed data structures, so:

can you go into a little more depth as to the workings of this? We
learned about hash tables in an algorithms class. Are they at all related?
Or only because there's a key/value pairing? In the hash tables, these keys
were generated by the hash function and unique.

They are all related in the sense that they are associative arrays, in
where the internal addressing is done using a hashed value as key, but
their inner working varies. In all of them, there's some conversion of
"something" to a hash value that then is mapped (usually with very simple
  modular arithmetics) to a position (a "bucket") in the data structure.
  The main benefit of a hash table relies on its sifting mechanism: during
  its operations, the hashtable can quickly discard buckets it positively
  knows the key/object you are going to insert/remove/access cannot be in
  those buckets.

You must not confuse keys with hash codes for those keys. You can have
different keys with the same hashCode (but NEVER different hashCodes for
  the same key). This condition is called hash collision, and it's not
  that uncommon. A hash collision is solved by allowing multiple entries
  per bucket. During key-based access with a key k1, the structure will
  first find the key's corresponding bucket by calculating k.hashCode(),
  then look through all of that bucket's contents for the value associated
  to a key k2 where k1.hashCode() == k2.hashCode() && k1.equals(k2).

When you say that the keys in a Hashtable are unique, it means that you
cannot have two equal keys pointing to different values (that would be a
  Multimap), not that you cannot have two keys with the same hashCode().
  You could even create an experimental project with a key class that
  returns a fixed arbitrary value and, as long as your implementation of
  equals() is correct, the structure will still work, although with almost
  no performance gain, as you will put all the inserted values on the same
  bucket, no matter what the key is -because all the keys return the same
  hashCode-. That hashtable would always work with the hash collision
  resolution logic, which can be slower than the normal logic.

What are these mainly used for?

SPEED. Hash tables can be used in any situation in which you need a fast
lookup structure with almost constant insertion, removal and access time,
independently of how many elements are contained in it. This advantage
becomes more noticeable with large amounts of data in.

Hashtables are able to work so fast at the expense of memory footprint: for
a hashtable to work correctly, it needs to have "spare" or empty buckets.
The relationship between the element count and the bucket count is called
load factor. For the same amount of data, the higher the load factor is,
the lower performance (and memory footprint) you will have: you have less
buckets -less memory is used by the structure- but more entries per bucket
-more collisions: more time needed to look for a value in them-,
conversely, the lower the load factor is, the higher the performance (and
  memory footprint) will be: hash collisions are minimized, as it will be
  more usual for each key to have its own bucket.

What happens if you try to load in an existing key with another value?
Does it overwrite, or throw an exception?

The java.util.Map spec states that the value associated to that key is
overriden. HashMap comes from Java2 collections and thus it was born a Map.
Hashtable comes from Java 1.0 and it was "retrofitted" as a java.util.Map
implentation in Java2. */
